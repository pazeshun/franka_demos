import rospy
from franka_teleop.srv import *
import tensorflow as tf
import tensorflow_probability as tfp

import pickle
import numpy as np
from rlbench.backend.observation import Observation
from PIL import Image

from integral.models.lstm import LSTM
from integral.agents.agent import Agent
from integral.models.image_vae import ConvVae


class ImitationAgentServer:

    def __init__(self, lstm_path, image_vae_path=None, action_dim=None):
        rospy.init_node('imitation_agent_server')
        self.srv = rospy.Service('imitation_agent', self.handle_srv)
        lstm_builder = LSTM(saved_model=lstm_path)
        self.lstm_model = lstm_builder.model
        if not image_vae_path:
            self._use_fake_embedding = True
        else:
            self._use_fake_embedding = False
            self.image_vae = ConvVae(saved_model=image_vae_path)
            self.image_encorder = self.image_vae.encoder
        self.action_dim = action_dim
        self.internal_count = 0

    def handle_srv(self, req):
        from IPython import embed; embed()

    def act(self, observation, action_size=None):
        if (action_size is None) and (self.action_dim is not None):
            action_size = self.action_dim
        obs = self._process_observation(observation)
        obs = np.expand_dims(np.expand_dims(obs, axis=0), axis=0)

        pred = self.lstm_model.predict(obs)[0][0]
        if action_size:
            # Here we are assuming that actions & flag are at the end of output vector.
            self.action = pred[-(action_size + 1):-1]
        else:
            # Output is purely actions & flag.
            self.action = pred[:-1]

        return self.action

    def reset(self):
        self.internal_count = 0
        self.action = None
        # resetting lstm internal memory
        self.lstm_model.reset_states()

    def get_predicted_trajectory(self, observation, steps=1, exclude_action=True, action_size=None):
        """Get n-step ahead trajectory that is generated by reccurent inference.
        The internal states of the all LSTM layers are restored to the initial internal state after inference.
        """
        if (action_size is None) and (self.action_dim is not None):
            action_size = self.action_dim
        obs = self._process_observation(observation)
        obs_first = obs  # first observatio feeded for model
        obs = np.expand_dims(np.expand_dims(obs, axis=0), axis=0)
        current_lstm_states = self._get_lstm_states()
        predicted_trajectory = []
        for i in range(steps):
            pred_obs = self.lstm_model.predict(obs)
            if exclude_action:
                predicted_trajectory.append(pred_obs[0][0][:-(self.action_dim + 1)])
            else:
                predicted_trajectory.append(pred_obs[0][0])
            obs = pred_obs
        predicted_trajectory = np.array(predicted_trajectory)
        self._restore_lstm_states(current_lstm_states)
        
        return obs_first, predicted_trajectory

    def _get_lstm_states(self) -> list:
        """Save lstm internal states (h and c)
        """
        states = []
        for l in self.lstm_model.layers:
            if 'lstm'in l.name:
                states.append([l.states[0].numpy(), l.states[1].numpy()])
        return states

    def _restore_lstm_states(self, states: list):
        """Restore lstm internal states (h and c)
        """
        idx = 0
        for l in self.lstm_model.layers:
            if 'lstm'in l.name:
                l.reset_states(states[idx])
                idx += 1
    
    @property
    def name(self):
        return self.lstm_model.name

    def get_predicted_state(self, obs, exclude_action=True, action_size=None):
        """Returns one step ahead prediction
        """
        return self.get_predicted_trajectory(obs, 1, exclude_action, action_size)[0]

    def _process_observation(self, obs_orig):
        """concatenate observations to make a vector for one instance time step.
        """
        if self._use_fake_embedding:
            emb = obs_orig.task_low_dim_state
            if self.input_vector_signature == 'emb-gp-ja-go':
                emb = np.concatenate((emb, obs_orig.gripper_pose))
        else:
            img = Image.fromarray(np.uint8(obs_orig.front_rgb * 255.0))
            input_shape = (self.image_encorder.input.shape[1], self.image_encorder.input.shape[2])
            img = np.array([np.array(img.resize(input_shape))])
            img = img/255.0
            emb = self.image_encorder([img])  # extract latent vector form image
            emb = np.array(emb).flatten()
        ja = obs_orig.joint_positions.flatten()
        go = np.array([obs_orig.gripper_open])
        return np.concatenate((emb, ja, go, [0]))
